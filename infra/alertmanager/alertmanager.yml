# =============================================================================
# AlertManager Configuration
# MedicalCor Medical CRM - Production Alerting
# =============================================================================

global:
  # SMTP configuration for email notifications
  smtp_smarthost: '${SMTP_HOST}:${SMTP_PORT}'
  smtp_from: 'alerts@medicalcor.io'
  smtp_auth_username: '${SMTP_USER}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_require_tls: true

  # Slack API URL (use webhook URL)
  slack_api_url: '${SLACK_WEBHOOK_URL}'

  # PagerDuty integration key
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

  # Global resolve timeout
  resolve_timeout: 5m

# Route tree configuration
route:
  # Default receiver for unmatched alerts
  receiver: 'default-receiver'

  # Group alerts by these labels
  group_by: ['alertname', 'severity', 'service']

  # Wait before sending first notification
  group_wait: 30s

  # Wait before sending subsequent notifications for a group
  group_interval: 5m

  # Wait before resending a notification
  repeat_interval: 4h

  # Child routes for specific alert types
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 1h
      continue: false

    # Warning alerts - less urgent
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 1m
      repeat_interval: 4h
      continue: false

    # Business hours alerts (leads, scoring)
    - match_re:
        alertname: '(NoLeadsScored|UnusualHotLeadVolume)'
      receiver: 'business-alerts'
      group_wait: 5m
      repeat_interval: 2h
      # Only during business hours (handled by time_intervals)
      active_time_intervals:
        - business-hours
      continue: false

    # AI/ML service alerts
    - match_re:
        alertname: '(AIServiceDegraded|AIScoringSlow)'
      receiver: 'ai-alerts'
      group_wait: 2m
      repeat_interval: 30m
      continue: false

    # Infrastructure alerts
    - match_re:
        alertname: '(RedisDown|HighMemoryUsage|LowDiskSpace)'
      receiver: 'infra-alerts'
      group_wait: 30s
      repeat_interval: 2h
      continue: false

# Receiver definitions
receivers:
  - name: 'default-receiver'
    email_configs:
      - to: 'devops@medicalcor.io'
        send_resolved: true

  - name: 'critical-alerts'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        severity: critical
        description: '{{ template "pagerduty.description" . }}'
        details:
          firing: '{{ template "pagerduty.firing" . }}'
    slack_configs:
      - channel: '#alerts-critical'
        send_resolved: true
        title: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ template "slack.critical.text" . }}'
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    email_configs:
      - to: 'oncall@medicalcor.io, cto@medicalcor.io'
        send_resolved: true
        headers:
          priority: 'urgent'

  - name: 'warning-alerts'
    slack_configs:
      - channel: '#alerts-warning'
        send_resolved: true
        title: '‚ö†Ô∏è Warning: {{ .GroupLabels.alertname }}'
        text: '{{ template "slack.warning.text" . }}'
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    email_configs:
      - to: 'devops@medicalcor.io'
        send_resolved: true

  - name: 'business-alerts'
    slack_configs:
      - channel: '#alerts-business'
        send_resolved: true
        title: 'üìä Business Alert: {{ .GroupLabels.alertname }}'
        text: '{{ template "slack.business.text" . }}'
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    email_configs:
      - to: 'operations@medicalcor.io'
        send_resolved: true

  - name: 'ai-alerts'
    slack_configs:
      - channel: '#alerts-ai'
        send_resolved: true
        title: 'ü§ñ AI Service Alert: {{ .GroupLabels.alertname }}'
        text: '{{ template "slack.ai.text" . }}'
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
    email_configs:
      - to: 'ml-team@medicalcor.io'
        send_resolved: true

  - name: 'infra-alerts'
    slack_configs:
      - channel: '#alerts-infrastructure'
        send_resolved: true
        title: 'üîß Infrastructure Alert: {{ .GroupLabels.alertname }}'
        text: '{{ template "slack.infra.text" . }}'
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    email_configs:
      - to: 'infrastructure@medicalcor.io'
        send_resolved: true

# Inhibition rules - suppress alerts when higher severity ones are firing
inhibit_rules:
  # If ServiceDown is firing, suppress all other alerts for that service
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*'
    equal: ['service']

  # If RedisDown is firing, suppress rate limit alerts
  - source_match:
      alertname: 'RedisDown'
    target_match:
      alertname: 'RateLimitExhausted'

  # Critical alerts suppress warning alerts for same alertname
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'service']

# Time intervals for business hours routing
time_intervals:
  - name: business-hours
    time_intervals:
      - times:
          - start_time: '08:00'
            end_time: '20:00'
        weekdays: ['monday:friday']
        location: 'Europe/Bucharest'

# Templates for notification formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'
